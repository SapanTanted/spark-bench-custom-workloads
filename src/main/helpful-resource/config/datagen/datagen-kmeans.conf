spark-bench = {
  spark-submit-parallel = false
  spark-submit-config = [{
    spark-bench-jar = "local:///opt/spark-bench/lib/spark-bench-2.3.0_0.4.0-RELEASE.jar"
    spark-args = {
      "master" = "k8s://https://10.129.2.177:6443"
      "deploy-mode"= "cluster"
      "jars"="hdfs://10.129.2.179:8020/jars/*,hdfs://10.129.2.179:8020/jars/dependency/*"
    }
    conf = {
        "spark.driver.cores" = "1"
        "spark.driver.memory" = "1g"
        "spark.executor.memory" = "1g"
        "spark.reducer.maxSizeInFlight" = "52m"
        "spark.shuffle.compress" = "true"
        "spark.shuffle.file.buffer" = "32k"
        "spark.shuffle.spill.compress" = "true"
        "spark.io.compression.codec" = "lz4"
        "spark.rdd.compress" = "false"
        "spark.memory.fraction" = "0.6"
        "spark.executor.cores" = "2"
        "spark.default.parallelism" = "2"
        "spark.locality.wait" = "3s"
        "spark.task.cpus" = "1"
        "spark.executor.instances" = "2"
   
    
        "spark.extraListeners" = "com.qubole.sparklens.QuboleJobListener"
        "spark.kubernetes.container.image"= "sapantanted/sparkrnd:spark-bench"
        "spark.kubernetes.authenticate.driver.serviceAccountName" = "spark"
        "spark.kubernetes.namespace" = "default"
        "spark.kubernetes.driver.pod.name"="datagen-sapan-kmeans-3"
        "spark.sparklens.data.dir" = "hdfs://10.129.2.179:8020/logs/datagen/sapan/kmeans-3/sparklens/"
    }
    suites-parallel = false
    workload-suites = [
      {
        benchmark-output = "hdfs://10.129.2.179:8020/logs/datagen/sapan/kmeans-3/benchmark-output.csv"
        parallel = false
        save-mode="overwrite"
        workloads = [
     	   {
            name = "data-generation-kmeans"
            rows = 12800000
            cols = 64
            k=32
            output = "hdfs://10.129.2.179:8020/input-data/datagen/kmeans-data-3.csv"
          }
        ]
      }
    ]
   }]
  }

